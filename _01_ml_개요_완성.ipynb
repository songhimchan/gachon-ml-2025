{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI 기술 발전의 이해\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PCVZEUPUNldz"
      },
      "id": "PCVZEUPUNldz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. 1950s~1980s: 규칙 기반** 전문가 시스템\n",
        "\n",
        "- **시나리오**: 체온, 기침/근육통/콧물 여부로 **감기 의심**을 규칙으로 판정\n",
        "- **목표**: 규칙 설계의 장단점 체감(명확하지만 유연성/확장성 한계)"
      ],
      "metadata": {
        "id": "VyeIk_EmBL7u"
      },
      "id": "VyeIk_EmBL7u"
    },
    {
      "cell_type": "code",
      "source": [
        "# 규칙 기반 진단기 (전문가 시스템 미니 버전)\n",
        "# Colab/Jupyter에서 바로 실행 가능\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Patient:\n",
        "    name: str\n",
        "    temperature: float  # 체온(℃)\n",
        "    cough: bool         # 기침\n",
        "    muscle_pain: bool   # 근육통\n",
        "    runny_nose: bool    # 콧물\n",
        "\n",
        "def diagnose_cold(p: Patient) -> str:\n",
        "    \"\"\"\n",
        "    간단 규칙:\n",
        "    - 고열(>= 37.8) + (기침 or 근육통 or 콧물) -> '감기 의심'\n",
        "    - 미열(37.3~37.7) + 증상 2개 이상 -> '감기 의심'\n",
        "    - 그 외 -> '정상 또는 기타'\n",
        "    \"\"\"\n",
        "    symptoms = sum([p.cough, p.muscle_pain, p.runny_nose])\n",
        "    if p.temperature >= 37.8 and symptoms >= 1:\n",
        "        return \"감기 의심\"\n",
        "    if 37.3 <= p.temperature < 37.8 and symptoms >= 2:\n",
        "        return \"감기 의심\"\n",
        "    return \"정상 또는 기타\"\n",
        "\n",
        "# 테스트\n",
        "patients = [\n",
        "    Patient(\"Alice\", 38.1, True, False, False),\n",
        "    Patient(\"Bob\", 37.5, True, True, False),\n",
        "    Patient(\"Charlie\", 36.8, False, False, True),\n",
        "    Patient(\"Dana\", 37.2, True, True, True),\n",
        "]\n",
        "\n",
        "for p in patients:\n",
        "    print(f\"{p.name}: {diagnose_cold(p)}\")\n",
        "\n",
        "# ▶ 확장실험:\n",
        "# 1) 규칙을 더 세밀화해보세요(예: 나이/기저질환).\n",
        "# 2) 모호 케이스(37.4℃, 증상 1개)를 어떻게 처리할지 팀 토론.\n"
      ],
      "metadata": {
        "id": "rj3N7AW7BMF5"
      },
      "id": "rj3N7AW7BMF5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **핵심 포인트**\n",
        "    -“설계자가 지식(규칙)을 직접 코딩” → 설명가능성↑, 데이터 불필요\n",
        "    - 그러나 새 증상/예외가 늘면 규칙 폭증 → 유지보수/일반화 한계"
      ],
      "metadata": {
        "id": "porJWCafe9ty"
      },
      "id": "porJWCafe9ty"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "v2oHDmQffFJO"
      },
      "id": "v2oHDmQffFJO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. 1990s: 고전 ML(SVM)으로 2D 분류 + 결정경계 시각화**\n",
        "\n",
        "- **시나리오**: 두 개의 2D 가우시안 분포에서 샘플을 뽑아 **SVM**으로 분류\n",
        "- **목표**: 데이터 → 학습 → 검증 → 결정경계 시각화의 표준 워크플로 이해"
      ],
      "metadata": {
        "id": "PLqmyxAqb3FP"
      },
      "id": "PLqmyxAqb3FP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **SVM(Support Vector Machine)**\n",
        "    - 분류(classification) 및 회귀(regression) 분석을 위한 강력한 지도 학습(supervised learning) 모델\n",
        "    - 분류 문제에서 뛰어난 성능을 보이며\n",
        "    - 데이터 포인트들을 효과적으로 분리하는 최적의 경계(결정 경계, decision boundary)를 찾아내는 것이 핵심 원리"
      ],
      "metadata": {
        "id": "DYuk3qa6chJQ"
      },
      "id": "DYuk3qa6chJQ"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-learn matplotlib numpy"
      ],
      "metadata": {
        "id": "j6fo53UddSxW"
      },
      "id": "j6fo53UddSxW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM 분류 (1990s 고전 ML 스타일)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# 1) 합성 데이터 생성 (두 개의 가우시안 분포)\n",
        "np.random.seed(42)\n",
        "n = 400\n",
        "mean1, cov1 = [0, 0], [[1.0, 0.3], [0.3, 1.0]]\n",
        "mean2, cov2 = [2.5, 2.0], [[1.0, -0.2], [-0.2, 1.2]]\n",
        "X1 = np.random.multivariate_normal(mean1, cov1, n//2)\n",
        "X2 = np.random.multivariate_normal(mean2, cov2, n//2)\n",
        "X = np.vstack([X1, X2])\n",
        "y = np.array([0]*(n//2) + [1]*(n//2))\n",
        "\n",
        "\n",
        "# 2) 학습/검증 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# 3) SVM 모델 학습 (RBF 커널)\n",
        "model = SVC(kernel='rbf', gamma='scale', C=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 4) 검증\n",
        "pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, pred)\n",
        "print(f\"Test Accuracy: {acc:.3f}\")\n",
        "\n",
        "\n",
        "# 5) 결정경계 시각화\n",
        "def plot_decision_boundary(clf, X, y, title=\"SVM Decision Boundary\"):\n",
        "    x_min, x_max = X[:,0].min()-1, X[:,0].max()+1\n",
        "    y_min, y_max = X[:,1].min()-1, X[:,1].max()+1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
        "                         np.linspace(y_min, y_max, 300))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.25)\n",
        "    plt.scatter(X[:,0], X[:,1], c=y, s=18, edgecolors='k')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(model, X, y, title=f\"SVM (RBF) | Test Acc={acc:.3f}\")\n",
        "\n",
        "\n",
        "# ▶ 확장실험:\n",
        "# - 커널 변경(linear, poly) 및 C, gamma 조절 → 결정경계 비교\n",
        "# - 표준화(Scaling) 전/후 성능 비교\n"
      ],
      "metadata": {
        "id": "QEEwpOflcgf2"
      },
      "id": "QEEwpOflcgf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **핵심 포인트**\n",
        "    - 데이터로부터 경계(결정 함수)를 학습\n",
        "    - 하이퍼파라미터(C, gamma)가 일반화 성능에 큰 영향\n",
        "    - 시각화로 모델 복잡도 ↔ 과적합 감각 익히기"
      ],
      "metadata": {
        "id": "Eo5YB87AejBV"
      },
      "id": "Eo5YB87AejBV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5du-xQOPfMbb"
      },
      "id": "5du-xQOPfMbb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. 2010s 이후: 딥러닝(MLP 분류)**\n",
        "\n",
        "- **시나리오**: 간단한 “손글씨 비슷한” 8×8 합성 이미지 데이터(숫자 0~9)를 **다층 퍼셉트론(MLP)** 으로 분류\n",
        "- **목표**: 딥러닝의 기본 학습 루프/과적합 관리(검증셋, EarlyStopping) 체험"
      ],
      "metadata": {
        "id": "ahZtyPgEeclp"
      },
      "id": "ahZtyPgEeclp"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow scikit-learn matplotlib"
      ],
      "metadata": {
        "id": "pLgB8J-JfqjY"
      },
      "id": "pLgB8J-JfqjY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝(2010s): Keras MLP로 8x8 손글씨(MNIST) 숫자 분류\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 1) 데이터 로드 (8x8 이미지, 1797 샘플)\n",
        "digits = load_digits()\n",
        "X = digits.images  # (n, 8, 8)\n",
        "y = digits.target  # (n,)\n",
        "\n",
        "\n",
        "# 2) 전처리: 평탄화 + 정규화\n",
        "X = X.reshape(len(X), -1).astype(\"float32\")  # (n, 64)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# 3) 학습/검증/테스트 분리\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=42, stratify=y_tmp)\n",
        "\n",
        "\n",
        "# 4) MLP 모델 정의\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(64,)),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# 5) EarlyStopping으로 과적합 제어\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 6) 학습\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(f\"Best Val Acc: {max(history.history['val_accuracy']):.3f}\")\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "\n",
        "# 7) 학습 곡선 시각화\n",
        "plt.figure()\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.legend()\n",
        "plt.title(\"MLP Training Curve\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 8) 예측 확인\n",
        "probs = model.predict(X_test[:8], verbose=0)\n",
        "preds = probs.argmax(axis=1)\n",
        "print(\"Pred:\", preds)\n",
        "print(\"True:\", y_test[:8].tolist())\n"
      ],
      "metadata": {
        "id": "i8RWnvoeb3Pc"
      },
      "id": "i8RWnvoeb3Pc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) 새로운 데이터 예측 함수\n",
        "def predict_digit(model, scaler, input_array):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : 학습된 Keras 모델\n",
        "    scaler : 학습 시 사용한 스케일러 (fit된 상태)\n",
        "    input_array : np.ndarray (64,) 형태의 1차원 배열 (8x8 이미지 평탄화된 형태)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pred_class : int 예측된 숫자 클래스 (0~9)\n",
        "    pred_probs : np.ndarray 각 클래스별 확률 (길이 10)\n",
        "    \"\"\"\n",
        "    # 입력을 2차원으로 reshape (모델 입력 크기 맞추기)\n",
        "    # 학습 때와 동일한 정규화 적용\n",
        "    arr = np.array(input_array).reshape(1, -1).astype(\"float32\")\n",
        "    arr = scaler.transform(arr)\n",
        "    # 예측\n",
        "    probs = model.predict(arr, verbose=0)\n",
        "    pred_class = probs.argmax(axis=1)[0]\n",
        "    return pred_class, probs[0]\n",
        "\n",
        "\n",
        "# 테스트: X_test에서 첫 샘플을 임의로 넣어보기\n",
        "sample = X_test[0] * 1.0  # 복사\n",
        "pred_class, pred_probs = predict_digit(model, scaler, sample)\n",
        "print(\"예측된 숫자:\", pred_class)\n",
        "print(\"클래스별 확률:\", np.round(pred_probs, 3))\n",
        "print(\"실제 정답:\", y_test[0])\n"
      ],
      "metadata": {
        "id": "fZktR6U3iQN9"
      },
      "id": "fZktR6U3iQN9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **핵심 포인트**\n",
        "    - 표현 학습: 모델이 특징을 자동 추출 (수작업 특징보다 유연)\n",
        "    - 일반화: 드롭아웃, EarlyStopping 등으로 과적합 방지\n",
        "    - 실전 확장: CNN(이미지), RNN/Transformer(시계열/자연어)로 확장 가능"
      ],
      "metadata": {
        "id": "0Py5baTFf6zH"
      },
      "id": "0Py5baTFf6zH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YQMhU0R-nOI4"
      },
      "id": "YQMhU0R-nOI4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. LLM(Large Language Model) 맛보기**"
      ],
      "metadata": {
        "id": "QWU0QzptnXH9"
      },
      "id": "QWU0QzptnXH9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **transformers** 라이브러리\n",
        "\n",
        "\n",
        "- **Hugging Face가 개발한 오픈소스 라이브러리(Transformer 모델 라이브러리)**\n",
        "- 자연어 처리, 컴퓨터 비전, 음성 등 다양한 분야의 최신 Transformer 기반 사전 학습된(pretrained) 모델을 쉽고 빠르게 사용할 수 있도록 지원함\n",
        "- 3개의 딥러닝 라이브러리 지원 :  PyTorch, TensorFlow, Jax\n",
        "- 상세설명 : https://pypi.org/project/transformers/\n"
      ],
      "metadata": {
        "id": "cCx9g4beNOpa"
      },
      "id": "cCx9g4beNOpa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **지원 플랫폼 / 요구사항**\n",
        "    - Python 3.9 이상, PyTorch 2.1+, TensorFlow 2.6+, Flax 0.4.1+\n",
        "- **용도 / 특징**\n",
        "    - 텍스트, 이미지, 오디오, 멀티모달 모델들처럼 다양한 영역의 pretrained 모델을 간단한 API(pipeline)로 빠르게 사용 가능\n",
        "- **추천 사용 케이스**\n",
        "    - 빠르고 쉽게 NLP, 컴퓨터 비전, 음성 등의 사전학습 모델을 사용하거나 fine-tuning 하고자 할 때"
      ],
      "metadata": {
        "id": "2SIij8mNSmaY"
      },
      "id": "2SIij8mNSmaY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **설치 방법**"
      ],
      "metadata": {
        "id": "_9dDQ0-2SDH2"
      },
      "id": "_9dDQ0-2SDH2"
    },
    {
      "cell_type": "code",
      "source": [
        "# 설치된 transformers 버전 확인  -->(ex: Version: 4.55.4)\n",
        "!pip show transformers | grep Version"
      ],
      "metadata": {
        "id": "YUQOtVxdYnhM"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YUQOtVxdYnhM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gioKeW2nK2zX"
      },
      "outputs": [],
      "source": [
        "# 다른 모델과 호환성 때문에 transformers 4.48.3 버전을 사용.\n",
        "!pip install transformers==4.48.3"
      ],
      "id": "gioKeW2nK2zX"
    },
    {
      "cell_type": "code",
      "source": [
        "# 설치된 PyTorch 버전 확인  -->(ex: Version: 2.8.0+cu126 (+cu126-->CUDA 12.6 버전 지원))\n",
        "!pip show torch | grep Version\n",
        "\n",
        "# pip install torch==2.8.0"
      ],
      "metadata": {
        "id": "iBbbJcLvujq4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "iBbbJcLvujq4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **QuickTour**"
      ],
      "metadata": {
        "id": "lNBhIvnzPGYD"
      },
      "id": "lNBhIvnzPGYD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **감정분석**"
      ],
      "metadata": {
        "id": "I-yv_vjYTEn9"
      },
      "id": "I-yv_vjYTEn9"
    },
    {
      "cell_type": "code",
      "source": [
        "# 감정 분석 파이프라인\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "print(classifier('We are very happy to introduce pipeline to the transformers repository.'))"
      ],
      "metadata": {
        "id": "kbODkmM0PL28"
      },
      "execution_count": null,
      "outputs": [],
      "id": "kbODkmM0PL28"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline(\"sentiment-analysis\")\n",
        "print(nlp(\"이 강의는 정말 재미있어요!\"))\n"
      ],
      "metadata": {
        "id": "2Dqi289eTARx"
      },
      "execution_count": null,
      "outputs": [],
      "id": "2Dqi289eTARx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **이미지 객체 감지**"
      ],
      "metadata": {
        "id": "5ADhlYgBTKT8"
      },
      "id": "5ADhlYgBTKT8"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image, ImageDraw\n",
        "from transformers import pipeline\n",
        "\n",
        "# 이미지 다운로드\n",
        "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"\n",
        "image_data = requests.get(url, stream=True).raw\n",
        "image = Image.open(image_data)\n",
        "\n",
        "# 객체 감지 파이프라인\n",
        "object_detector = pipeline(\"object-detection\")\n",
        "results = object_detector(image)\n",
        "\n",
        "# 원본 이미지에 바운딩 박스 그리기\n",
        "draw = ImageDraw.Draw(image)\n",
        "\n",
        "for result in results:\n",
        "    box = result[\"box\"]\n",
        "    label = result[\"label\"]\n",
        "    score = result[\"score\"]\n",
        "\n",
        "    # 박스 좌표\n",
        "    x1, y1, x2, y2 = box[\"xmin\"], box[\"ymin\"], box[\"xmax\"], box[\"ymax\"]\n",
        "\n",
        "    # 박스 그리기\n",
        "    draw.rectangle(((x1, y1), (x2, y2)), outline=\"red\", width=3)\n",
        "    # 레이블 + 점수 표시\n",
        "    draw.text((x1, y1 - 10), f\"{label} {score:.2f}\", fill=\"yellow\")\n",
        "\n",
        "# 결과 출력 (Colab 환경에서 시각화)\n",
        "image.show()   # 로컬 환경이면 새 창\n",
        "display(image) # Colab/Jupyter 환경이면 노트북 안에 표시\n"
      ],
      "metadata": {
        "id": "8GYQrUE5pBmX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "8GYQrUE5pBmX"
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### **[참고] Access Token 넣고 비공개 모델 접근**\n",
        "- https://huggingface.co/settings/tokens  로그인 후 사용하고자 하는 모델에 대한 access용 토큰 발급"
      ],
      "metadata": {
        "id": "yPeGS1yncJm0"
      },
      "id": "yPeGS1yncJm0"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1단계: Hugging Face 토큰 생성 및 설정\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "# Google Colab에서 토큰 입력 (한 번만 실행)\n",
        "# https://huggingface.co/settings/tokens 에서 토큰 생성 후 입력\n",
        "login()\n",
        "\n",
        "# 또는 직접 토큰 입력 (보안상 권장하지 않음)\n",
        "# os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = \"your_token_here\""
      ],
      "metadata": {
        "id": "BVqNfPWtvC2E"
      },
      "execution_count": null,
      "outputs": [],
      "id": "BVqNfPWtvC2E"
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import login\n",
        "# login(\"hf_xxxxxxxxxxxxx\")\n",
        "\n",
        "# from transformers import AutoModel\n",
        "# model = AutoModel.from_pretrained(\"username/private-model\")\n"
      ],
      "metadata": {
        "id": "j8RA42UEcJy1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "j8RA42UEcJy1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "69ZO4NC1l-Js"
      },
      "id": "69ZO4NC1l-Js"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}