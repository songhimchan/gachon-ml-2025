{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 지도학습 이해\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PCVZEUPUNldz"
      },
      "id": "PCVZEUPUNldz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. 지도학습(supervised learning) 이해**\n",
        "- 정답(label)이 주어진 데이터를 이용해 모델을 학습시키는 기계학습 방식\n",
        "- 모델은 입력(X)과 출력(Y) 간의 관계를 학습하고, 새로운 입력에 대한 예측을 수행"
      ],
      "metadata": {
        "id": "mcvw1xqqXRQP"
      },
      "id": "mcvw1xqqXRQP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[실습] 자연어 처리(NLP) 분야에서의 지도학습(분류) 예**\n"
      ],
      "metadata": {
        "id": "cJ3tF5MFFB2o"
      },
      "id": "cJ3tF5MFFB2o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjvcIpHmGuFF"
      },
      "source": [
        "#### **예제1. 텍스트 분류(뉴스 주제 분류)**\n",
        "- **태스크** : 뉴스 주제 분류\n",
        "- **문제유형** :  다중 클래스 분류\n",
        "- **데이터셋** :  20 newsgroups(scikit_learn 내장)\n",
        "- **특징추출** : TF-IDF(N-gram: bigram)\n",
        "- **분류기** :  logistic regression\n",
        "- **핵심내용**: 가장 기본적인 문서 분류 파이프라인"
      ],
      "id": "QjvcIpHmGuFF"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AhUYjyga-mAw",
        "outputId": "4eb9c253-b804-478b-9919-6e852a770bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8579691516709511\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "        comp.graphics       0.89      0.86      0.87       389\n",
            "   rec.sport.baseball       0.81      0.89      0.85       397\n",
            "            sci.space       0.85      0.82      0.84       394\n",
            "talk.politics.mideast       0.89      0.86      0.87       376\n",
            "\n",
            "             accuracy                           0.86      1556\n",
            "            macro avg       0.86      0.86      0.86      1556\n",
            "         weighted avg       0.86      0.86      0.86      1556\n",
            "\n",
            "[2 0 1 1]\n",
            "['sci.space', 'comp.graphics', 'rec.sport.baseball', 'rec.sport.baseball']\n"
          ]
        }
      ],
      "source": [
        "# --- 1. 텍스트 분류: 20 Newsgroups ---\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "# 1) 데이터 로드 (훈련/테스트 분리 제공)\n",
        "cats = ['sci.space', 'rec.sport.baseball', 'comp.graphics', 'talk.politics.mideast']\n",
        "train = fetch_20newsgroups(subset='train', categories=cats, remove=('headers','footers','quotes'))\n",
        "test  = fetch_20newsgroups(subset='test',  categories=cats, remove=('headers','footers','quotes'))\n",
        "\n",
        "\n",
        "# 2) 파이프라인: TF-IDF → 로지스틱 회귀(멀티클래스)\n",
        "pipe = make_pipeline(TfidfVectorizer(min_df=3, ngram_range=(1,2)),\n",
        "                     LogisticRegression(max_iter=300))\n",
        "\n",
        "\n",
        "# 3) 학습\n",
        "pipe.fit(train.data, train.target)\n",
        "\n",
        "\n",
        "# 4) 평가\n",
        "pred = pipe.predict(test.data)\n",
        "print(\"Accuracy:\", accuracy_score(test.target, pred))\n",
        "print(classification_report(test.target, pred, target_names=test.target_names))\n",
        "\n",
        "\n",
        "# 5) 사용 예시\n",
        "sample = [\"SpaceX just launched another rocket to the ISS.\",\n",
        "          \"OpenGL shaders can speed up graphics rendering.\",\n",
        "          \"The team won the baseball world series!\",\n",
        "          \"The negotiation in the middle east escalated.\"]\n",
        "print(pipe.predict(sample))          # 예측된 정수 라벨\n",
        "print([test.target_names[i] for i in pipe.predict(sample)])  # 라벨 이름\n"
      ],
      "id": "AhUYjyga-mAw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **예제2. 감성 분류(긍/부정)**\n",
        "NLTK의 movie_reviews 코퍼스(긍/부정 라벨)를 사용해 문서 분류(이진 분류)를 수행합니다.\n",
        "\n",
        "- **태스크** : 감석 분석\n",
        "- **문제유형** :  이진 분류\n",
        "- **데이터셋** :  nltk, movie_reviews\n",
        "- **특징추출** : TF-IDF(N-gram: bigram)\n",
        "- **분류기** :  Linear SVM\n",
        "- **핵심내용**: 리뷰 텍스트의 긍/부정 판"
      ],
      "metadata": {
        "id": "_brMjLktJrao"
      },
      "id": "_brMjLktJrao"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. 감성 분석: NLTK movie_reviews (긍/부정) ---\n",
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "from nltk.corpus import movie_reviews\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# 1) 문서/라벨 구성\n",
        "docs = []\n",
        "labels = []\n",
        "for cat in movie_reviews.categories():          # 'pos', 'neg'\n",
        "    for fid in movie_reviews.fileids(cat):\n",
        "        docs.append(movie_reviews.raw(fid))\n",
        "        labels.append(cat)\n",
        "\n",
        "# 2) 학습/검증 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    docs, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# 3) 파이프라인: TF-IDF → Linear SVM\n",
        "pipe = make_pipeline(TfidfVectorizer(min_df=3, ngram_range=(1,2)),\n",
        "                     LinearSVC())\n",
        "\n",
        "# 4) 학습 & 평가\n",
        "pipe.fit(X_train, y_train)\n",
        "pred = pipe.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "# 5) 사용 예시\n",
        "samples = [\n",
        "    \"What a wonderful movie! Brilliant acting and a touching story.\",\n",
        "    \"It was boring and way too long. I wouldn't recommend it.\"\n",
        "]\n",
        "print(pipe.predict(samples))  # ['pos', 'neg'] 예상\n"
      ],
      "metadata": {
        "id": "YPfSobv_cllS"
      },
      "id": "YPfSobv_cllS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LOWA7jQGuFH"
      },
      "source": [
        "#### **예제3. 품사 태깅(POS Tagging)**\n",
        "토큰 단위로 품사 라벨(POS tag) 를 예측하는 시퀀스 라벨링을, 간단한 맥락 기반 특징 + 로지스틱 회귀로 구현\n",
        "- **태스크** : 품사 태깅\n",
        "- **문제유형** : 시퀀스 라벨링(토큰 단위 분류)\n",
        "- **데이터셋** :  \n",
        "- **특징추출** : 주변 단어/점미사 등 수작업 특징\n",
        "- **분류기** :  \n",
        "- **핵심내용**: 지도학습의 핵심인 특징-->라벨) 체"
      ],
      "id": "8LOWA7jQGuFH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj_L_F9RH5B0"
      },
      "outputs": [],
      "source": [
        "# --- 3. 품사 태깅: NLTK treebank + 간단 특징 + 로지스틱 회귀 ---\n",
        "import nltk\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "from nltk.corpus import treebank\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1) (단어, 태그) 시퀀스 불러오기 (보편 태그셋 사용: NOUN, VERB, ADJ 등)\n",
        "sents = treebank.tagged_sents(tagset='universal')\n",
        "\n",
        "# 간단한 특징 함수: 현재/이전/다음 단어, 접미사/대문자/숫자 등\n",
        "def token_features(sent_words, i):\n",
        "    w = sent_words[i]\n",
        "    prev_w = sent_words[i-1] if i-1 >= 0 else \"<BOS>\"\n",
        "    next_w = sent_words[i+1] if i+1 < len(sent_words) else \"<EOS>\"\n",
        "    feats = {\n",
        "        \"w.lower\": w.lower(),\n",
        "        \"w.isupper\": w.isupper(),\n",
        "        \"w.isdigit\": w.isdigit(),\n",
        "        \"w.suffix2\": w[-2:].lower(),\n",
        "        \"w.suffix3\": w[-3:].lower(),\n",
        "        \"prev.lower\": prev_w.lower(),\n",
        "        \"next.lower\": next_w.lower(),\n",
        "        \"prev.isupper\": prev_w.isupper() if isinstance(prev_w, str) else False,\n",
        "        \"next.isupper\": next_w.isupper() if isinstance(next_w, str) else False,\n",
        "    }\n",
        "    return feats\n",
        "\n",
        "# 2) 특징/라벨 벡터 만들기\n",
        "X_dict, y = [], []\n",
        "for sent in sents:\n",
        "    words = [w for w, t in sent]\n",
        "    tags  = [t for w, t in sent]\n",
        "    for i in range(len(words)):\n",
        "        X_dict.append(token_features(words, i))\n",
        "        y.append(tags[i])\n",
        "\n",
        "# 3) 훈련/테스트 분리\n",
        "X_train_dict, X_test_dict, y_train, y_test = train_test_split(\n",
        "    X_dict, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 4) Dict → 벡터화 → 로지스틱 회귀\n",
        "vec = DictVectorizer(sparse=True)\n",
        "X_train = vec.fit_transform(X_train_dict)\n",
        "X_test  = vec.transform(X_test_dict)\n",
        "\n",
        "clf = LogisticRegression(max_iter=300, n_jobs=None, multi_class='auto')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 5) 평가\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Token-level Accuracy:\", accuracy_score(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "id": "Hj_L_F9RH5B0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[실습] 자연어 처리(NLP) 분야에서의 지도학습(회귀) 예**"
      ],
      "metadata": {
        "id": "Op84MOfWS-pO"
      },
      "id": "Op84MOfWS-pO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **예제1 : 영화 리뷰 감정 점수 예측 (1-5점 척도)**"
      ],
      "metadata": {
        "id": "_Ewf8k1dTBco"
      },
      "id": "_Ewf8k1dTBco"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# 샘플 데이터 생성\n",
        "reviews = [\n",
        "    \"This movie was absolutely amazing! Perfect story and acting.\",\n",
        "    \"Great film with excellent cinematography and soundtrack.\",\n",
        "    \"It was okay, nothing special but watchable.\",\n",
        "    \"Not my favorite, but had some good moments.\",\n",
        "    \"Terrible movie, waste of time and money.\",\n",
        "    \"Outstanding performance by all actors!\",\n",
        "    \"Average movie with predictable plot.\"\n",
        "]\n",
        "\n",
        "ratings = [5.0, 4.5, 3.0, 2.5, 1.0, 4.8, 3.2]\n",
        "\n",
        "# 텍스트 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    # 소문자 변환\n",
        "    text = text.lower()\n",
        "    # 특수문자 제거\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# 전처리 적용\n",
        "processed_reviews = [preprocess_text(review) for review in reviews]\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
        "X = vectorizer.fit_transform(processed_reviews)\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, ratings, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 선형 회귀 모델 훈련\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.3f}\")\n",
        "print(f\"R² Score: {r2:.3f}\")\n",
        "print(f\"실제값: {y_test}\")\n",
        "print(f\"예측값: {y_pred}\")\n",
        "\n",
        "print()\n",
        "상대오차율 = ((y_test - y_pred) / y_test) * 100\n",
        "print(f\"상대오차율: {상대오차율}%\")"
      ],
      "metadata": {
        "id": "agvUUeXwTCQx"
      },
      "id": "agvUUeXwTCQx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **예제2 : 텍스트 가독성 점수 예측**"
      ],
      "metadata": {
        "id": "uFm6BXesTBqU"
      },
      "id": "uFm6BXesTBqU"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat"
      ],
      "metadata": {
        "id": "QhjFxsvITjIh"
      },
      "id": "QhjFxsvITjIh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textstat\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 샘플 텍스트와 가독성 점수 (Flesch Reading Ease 기준)\n",
        "texts = [\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"Artificial intelligence represents a paradigm shift in computational methodologies.\",\n",
        "    \"Machine learning algorithms can process large amounts of data efficiently.\",\n",
        "    \"Deep learning uses neural networks with multiple layers.\",\n",
        "    \"This is a simple sentence that anyone can understand easily.\"\n",
        "]\n",
        "\n",
        "# 실제 Flesch Reading Ease 점수 계산\n",
        "readability_scores = [textstat.flesch_reading_ease(text) for text in texts]\n",
        "\n",
        "# 특징 추출 (문장 길이, 단어 수, 음절 수 등)\n",
        "def extract_features(text):\n",
        "    words = text.split()\n",
        "    sentences = text.split('.')\n",
        "\n",
        "    return [\n",
        "        len(words),  # 단어 수\n",
        "        len(sentences),  # 문장 수\n",
        "        sum(len(word) for word in words) / len(words),  # 평균 단어 길이\n",
        "        textstat.syllable_count(text),  # 음절 수\n",
        "        len(text)  # 총 글자 수\n",
        "    ]\n",
        "\n",
        "# 특징 벡터 생성\n",
        "features = [extract_features(text) for text in texts]\n",
        "X = np.array(features)\n",
        "y = np.array(readability_scores)\n",
        "\n",
        "# 정규화\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Random Forest 회귀 모델\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_scaled, y)\n",
        "\n",
        "# 새로운 텍스트 예측\n",
        "new_text = \"Python is a programming language that is easy to learn and use.\"\n",
        "new_features = scaler.transform([extract_features(new_text)])\n",
        "predicted_score = rf_model.predict(new_features)[0]\n",
        "\n",
        "print(f\"새로운 텍스트: {new_text}\")\n",
        "print(f\"예측된 가독성 점수: {predicted_score:.2f}\")\n",
        "print(f\"실제 가독성 점수: {textstat.flesch_reading_ease(new_text):.2f}\")\n",
        "\n",
        "print()\n",
        "actual = textstat.flesch_reading_ease(new_text)\n",
        "상대오차율 = ((actual - predicted_score) / actual) * 100\n",
        "print(f\"상대오차율: {상대오차율:.2f}%\")"
      ],
      "metadata": {
        "id": "vxgZah7VTCnJ"
      },
      "id": "vxgZah7VTCnJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **예제3 : 문서 유사도 점수 예측**"
      ],
      "metadata": {
        "id": "_HGmR2QETB0E"
      },
      "id": "_HGmR2QETB0E"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "\n",
        "# 샘플 문서 쌍과 유사도 점수\n",
        "doc_pairs = [\n",
        "    (\"The weather is nice today\", \"Today has beautiful weather\"),\n",
        "    (\"I love programming\", \"Programming is my passion\"),\n",
        "    (\"The cat is sleeping\", \"The dog is running\"),\n",
        "    (\"Machine learning is fascinating\", \"AI and ML are interesting topics\"),\n",
        "    (\"Python is great for data science\", \"Data analysis with Python is powerful\")\n",
        "]\n",
        "\n",
        "# 실제 유사도 점수 (코사인 유사도 기반)\n",
        "similarity_scores = []\n",
        "for doc1, doc2 in doc_pairs:\n",
        "    vectorizer = CountVectorizer().fit([doc1, doc2])\n",
        "    vectors = vectorizer.transform([doc1, doc2])\n",
        "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
        "    similarity_scores.append(similarity)\n",
        "\n",
        "# 특징 추출 (두 문서의 특징 결합)\n",
        "def extract_pair_features(doc1, doc2):\n",
        "    # 기본 통계\n",
        "    len_diff = abs(len(doc1.split()) - len(doc2.split()))\n",
        "\n",
        "    # 공통 단어 수\n",
        "    words1 = set(doc1.lower().split())\n",
        "    words2 = set(doc2.lower().split())\n",
        "    common_words = len(words1.intersection(words2))\n",
        "\n",
        "    # Jaccard 유사도\n",
        "    jaccard_sim = len(words1.intersection(words2)) / len(words1.union(words2))\n",
        "\n",
        "    return [len_diff, common_words, jaccard_sim]\n",
        "\n",
        "# 특징 벡터 생성\n",
        "features = [extract_pair_features(doc1, doc2) for doc1, doc2 in doc_pairs]\n",
        "X = np.array(features)\n",
        "y = np.array(similarity_scores)\n",
        "\n",
        "# SVR 모델 훈련\n",
        "svr_model = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
        "svr_model.fit(X, y)\n",
        "\n",
        "# 예측 테스트\n",
        "test_pair = (\"Deep learning networks\", \"Neural networks for AI\")\n",
        "test_features = np.array([extract_pair_features(test_pair[0], test_pair[1])])\n",
        "predicted_similarity = svr_model.predict(test_features)[0]\n",
        "\n",
        "print(f\"테스트 문서 쌍:\")\n",
        "print(f\"문서 1: {test_pair[0]}\")\n",
        "print(f\"문서 2: {test_pair[1]}\")\n",
        "print(f\"예측된 유사도: {predicted_similarity:.3f}\")\n",
        "\n",
        "# 실제 코사인 유사도와 비교\n",
        "vectorizer = CountVectorizer().fit(test_pair)\n",
        "vectors = vectorizer.transform(test_pair)\n",
        "actual_similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
        "print(f\"실제 코사인 유사도: {actual_similarity:.3f}\")\n",
        "\n",
        "print()\n",
        "상대오차율 = ((actual_similarity - predicted_similarity) / actual_similarity) * 100\n",
        "print(f\"상대오차율: {상대오차율:.2f}%\")"
      ],
      "metadata": {
        "id": "9DEcH4wlTC95"
      },
      "id": "9DEcH4wlTC95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NfOPlbYULOSR"
      },
      "id": "NfOPlbYULOSR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. AI 모델링 프로세스**"
      ],
      "metadata": {
        "id": "X_mujQclLNMV"
      },
      "id": "X_mujQclLNMV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IrX2xVfCLNQM"
      },
      "id": "IrX2xVfCLNQM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. 학습데이터 분할 방법**"
      ],
      "metadata": {
        "id": "69ZboNqcLnXv"
      },
      "id": "69ZboNqcLnXv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예제 : K-Fold 교차검증 (회귀)"
      ],
      "metadata": {
        "id": "GTkAgDPZZRsK"
      },
      "id": "GTkAgDPZZRsK"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 데이터 생성\n",
        "# X, y = make_regression(n_samples=1000, n_features=10, noise=10, random_state=42)\n",
        "# X, y = make_regression(\n",
        "#     n_samples=200,      # 작은 데이터셋\n",
        "#     n_features=15,      # 특징 수 증가\n",
        "#     n_informative=8,    # 유용한 특징 수\n",
        "#     noise=30,           # 높은 노이즈\n",
        "#     random_state=42\n",
        "# )\n",
        "# # 더 큰 차이를 보이는 데이터\n",
        "X, y = make_regression(\n",
        "    n_samples=100,      # 매우 작은 데이터셋\n",
        "    n_features=20,      # 특징 수 더 증가\n",
        "    n_informative=5,    # 유용한 특징은 적게\n",
        "    noise=50,           # 매우 높은 노이즈\n",
        "    random_state=123    # 다른 시드값\n",
        ")\n",
        "\n",
        "def compare_evaluation_methods(X, y):\n",
        "    \"\"\"\n",
        "    단일 분할 vs K-Fold 교차검증 간단 비교\n",
        "    \"\"\"\n",
        "    print(\"=== 교차검증 유무 비교 ===\")\n",
        "\n",
        "    # 1. 단일 분할 (교차검증 X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    single_r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # 2. K-Fold 교차검증 (교차검증 O)\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    cv_scores = cross_val_score(LinearRegression(), X, y, cv=kfold, scoring='r2')\n",
        "    kfold_r2_mean = cv_scores.mean()\n",
        "    kfold_r2_std = cv_scores.std()\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"단일 분할 R²: {single_r2:.3f}\")\n",
        "    print(f\"K-Fold    R²: {kfold_r2_mean:.3f} ± {kfold_r2_std:.3f}\")\n",
        "    print(f\"차이: {abs(single_r2 - kfold_r2_mean):.3f}\")\n",
        "\n",
        "    if kfold_r2_std < 0.05:\n",
        "        print(\"✅ K-Fold 결과가 안정적입니다.\")\n",
        "    else:\n",
        "        print(\"⚠️ 성능 변동이 있습니다.\")\n",
        "\n",
        "# 실행\n",
        "compare_evaluation_methods(X, y)"
      ],
      "metadata": {
        "id": "Jwxg5bxyZR1b"
      },
      "id": "Jwxg5bxyZR1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [실습] 학습 데이터 분할 방법 테스트\n",
        "- 앞의 **2.감성 분류 과정**에서 학습/테스트 데이터 분류를 5:5, 9:1로 했을 때 모델의 정확도가 변동이 있는지 확인해 보세요.\n",
        "- **8:1** = Accuracy: **0.87**\n",
        "- **5:5** = Accuracy: **?**\n",
        "- **9:1** = Accuracy: **?**"
      ],
      "metadata": {
        "id": "FGyTgeBzMMBB"
      },
      "id": "FGyTgeBzMMBB"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. 감성 분석: NLTK movie_reviews (긍/부정) ---\n",
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "from nltk.corpus import movie_reviews\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# 1) 문서/라벨 구성\n",
        "docs = []\n",
        "labels = []\n",
        "for cat in movie_reviews.categories():          # 'pos', 'neg'\n",
        "    for fid in movie_reviews.fileids(cat):\n",
        "        docs.append(movie_reviews.raw(fid))\n",
        "        labels.append(cat)\n"
      ],
      "metadata": {
        "id": "-pWdlhC_Mt-N"
      },
      "id": "-pWdlhC_Mt-N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **조건1: 학습:테스트=5:5**"
      ],
      "metadata": {
        "id": "aM1pLCKfMuvD"
      },
      "id": "aM1pLCKfMuvD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0ywO_s4S98S"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ],
      "id": "z0ywO_s4S98S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **조건2: 학습:테스트=9:1**"
      ],
      "metadata": {
        "id": "aRWc89ukfTpj"
      },
      "id": "aRWc89ukfTpj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W7R0Z27fTpk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ],
      "id": "7W7R0Z27fTpk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MIKJjgsyLnhO"
      },
      "id": "MIKJjgsyLnhO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RU-Qs13GuFI"
      },
      "source": [
        "## **4.모델 평가 방법**"
      ],
      "id": "-RU-Qs13GuFI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예제 : 회귀모델 평가지표"
      ],
      "metadata": {
        "id": "uLXB79xlcV8g"
      },
      "id": "uLXB79xlcV8g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "|지표 | 공식 | 특징  | 해석 |\n",
        "|---|---|---|--|\n",
        "|MSE  | 평균((실제-예측)²) | 이상치에 민감 | 작을수록 좋음 |\n",
        "|MAE평균 | (|실제-예측|) | 이상치에 강건 | 작을수록 좋음|\n",
        "|R² | 1 - (오차분산/전체분산) | 설명력 측정 | 1에 가까울수록 좋음 |"
      ],
      "metadata": {
        "id": "LwgeF8HUdFSY"
      },
      "id": "LwgeF8HUdFSY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djyDIbjmTDag"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 샘플 데이터 생성\n",
        "X, y = make_regression(n_samples=100, n_features=5, noise=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 훈련 및 예측\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== 회귀 모델 평가지표 3가지 ===\")\n",
        "print(f\"실제값 예시: {y_test[:5]}\")\n",
        "print(f\"예측값 예시: {y_pred[:5]}\")\n",
        "\n",
        "# 1. MSE (Mean Squared Error) - 평균 제곱 오차\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"\\n1️⃣ MSE: {mse:.2f}\")\n",
        "print(\"   의미: 오차의 제곱 평균 (이상치에 민감)\")\n",
        "print(\"   해석: 값이 작을수록 좋음\")\n",
        "\n",
        "# 2. MAE (Mean Absolute Error) - 평균 절대 오차\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"\\n2️⃣ MAE: {mae:.2f}\")\n",
        "print(\"   의미: 오차의 절댓값 평균 (이상치에 강건)\")\n",
        "print(\"   해석: 값이 작을수록 좋음, 직관적 이해 쉬움\")\n",
        "\n",
        "# 3. R² Score - 결정계수\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"\\n3️⃣ R² Score: {r2:.3f}\")\n",
        "print(\"   의미: 모델이 설명하는 분산 비율\")\n",
        "print(\"   해석: 0~1, 1에 가까울수록 좋음\")\n",
        "\n",
        "# 간단한 성능 평가\n",
        "if r2 > 0.8:\n",
        "    print(\"\\n✅ 우수한 모델 성능\")\n",
        "elif r2 > 0.6:\n",
        "    print(\"\\n✅ 양호한 모델 성능\")\n",
        "else:\n",
        "    print(\"\\n⚠️ 모델 개선 필요\")"
      ],
      "id": "djyDIbjmTDag"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 예제 : 분류모델 평가지표"
      ],
      "metadata": {
        "id": "pvuBcp_ecq63"
      },
      "id": "pvuBcp_ecq63"
    },
    {
      "cell_type": "markdown",
      "source": [
        "|지표 | 공식 | 언제 중요한가 | 해석|\n",
        "|---|---|---|--|\n",
        "|Accuracy | (TP+TN)/(TP+TN+FP+FN) | 클래스가 균형잡힌 경우 | 1에 가까울수록 좋음|\n",
        "|Precision | TP/(TP+FP) | 오탐(False Positive)이 치명적일 때 | 1에 가까울수록 좋음|\n",
        "|Recall | TP/(TP+FN) | 놓침(False Negative)이 치명적일 때 | 1에 가까울수록 좋음|\n",
        "|F1-Score | 2×(Precision×Recall)/(Precision+Recall) | 균형잡힌 평가가 필요할 때 | 1에 가까울수록 좋음|"
      ],
      "metadata": {
        "id": "Vyqwhp8GdnyR"
      },
      "id": "Vyqwhp8GdnyR"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# 샘플 분류 데이터 생성\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 훈련 및 예측\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== 분류 모델 평가지표 4가지 ===\")\n",
        "print(f\"실제값 예시: {y_test[:10]}\")\n",
        "print(f\"예측값 예시: {y_pred[:10]}\")\n",
        "\n",
        "# 1. Accuracy (정확도)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n1️⃣ Accuracy: {accuracy:.3f}\")\n",
        "print(\"   의미: 전체 중 맞게 예측한 비율\")\n",
        "print(\"   해석: 1에 가까울수록 좋음\")\n",
        "\n",
        "# 2. Precision (정밀도)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(f\"\\n2️⃣ Precision: {precision:.3f}\")\n",
        "print(\"   의미: 양성으로 예측한 것 중 실제 양성인 비율\")\n",
        "print(\"   해석: 거짓 양성(오탐)을 줄이고 싶을 때 중요\")\n",
        "\n",
        "# 3. Recall (재현율)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(f\"\\n3️⃣ Recall: {recall:.3f}\")\n",
        "print(\"   의미: 실제 양성 중 올바르게 예측한 비율\")\n",
        "print(\"   해석: 거짓 음성(놓침)을 줄이고 싶을 때 중요\")\n",
        "\n",
        "# 4. F1-Score (F1 점수)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"\\n4️⃣ F1-Score: {f1:.3f}\")\n",
        "print(\"   의미: Precision과 Recall의 조화평균\")\n",
        "print(\"   해석: 균형잡힌 성능 평가\")\n",
        "\n",
        "# 혼동행렬 (Confusion Matrix)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\n📊 혼동행렬:\")\n",
        "print(f\"   실제\\\\예측   0    1\")\n",
        "print(f\"        0    {cm[0,0]:3}  {cm[0,1]:3}\")\n",
        "print(f\"        1    {cm[1,0]:3}  {cm[1,1]:3}\")\n",
        "\n",
        "# 간단한 성능 평가\n",
        "print(f\"\\n=== 성능 평가 ===\")\n",
        "if accuracy > 0.9:\n",
        "    print(\"✅ 매우 우수한 성능\")\n",
        "elif accuracy > 0.8:\n",
        "    print(\"✅ 우수한 성능\")\n",
        "elif accuracy > 0.7:\n",
        "    print(\"✅ 양호한 성능\")\n",
        "else:\n",
        "    print(\"⚠️ 성능 개선 필요\")\n",
        "\n",
        "# 정밀도 vs 재현율 트레이드오프\n",
        "if precision > recall:\n",
        "    print(\"📈 정밀도가 높음: 오탐이 적음\")\n",
        "else:\n",
        "    print(\"📈 재현율이 높음: 놓치는 것이 적음\")"
      ],
      "metadata": {
        "id": "pwmeoI5Ucwta"
      },
      "id": "pwmeoI5Ucwta",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[Tip] 모델의 파라미터 확인하는 방법**"
      ],
      "metadata": {
        "id": "Pc3lV6uLEFr4"
      },
      "id": "Pc3lV6uLEFr4"
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 파라미터 확인하는 방법\n",
        "print(model.get_params().keys())  # 파라미터 이름들\n",
        "print(model.get_params())         # 파라미터 전체와 값"
      ],
      "metadata": {
        "id": "4bOVE-2nDtdV"
      },
      "id": "4bOVE-2nDtdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "69ZO4NC1l-Js"
      },
      "id": "69ZO4NC1l-Js"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}